[{"content":"原文地址\n1. 简介 生成扩散模型将物理学中的朗之万动力学概念应用于机器学习，吸引了工程学、统计学和物理学领域的广泛关注，但对其内在机制的完整描述仍然缺乏。本文对扩散模型进行了清晰的物理分析，运用涨落定理、熵产生、平衡测度和弗朗兹-帕里西势来理解动态过程和内在相变。分析基于正向和反向动力学的路径积分表示，并将反向扩散生成过程视为统计推断，其中时间相关的状态变量充当类似于自旋玻璃理论中的猝灭无序。最终这个研究将随机热力学、统计推断和基于几何的分析联系在一起，从而对生成扩散模型的工作原理给出了一个连贯的描述。\n2. 背景知识 2.1 生成扩散模型\u0026ndash;以DDPM为例 这里以DDPM讲解生成扩散模型的基本数学过程。 逆过程：数据\\(\\mathbf{x}_0\\)，潜空间变量$\\mathbf{x}_1...\\mathbf{x}_T$，这一系列变量的联合分布$p_{\\theta}(\\mathbf{x}_{0:T})$被称为逆过程 首先对于数据与所对应的潜变量的系列运动过程定义为高斯过程的马尔可夫链，那么得到起点$p(\\mathbf{x}_T)=\\mathcal{N}(\\mathbf{x}_T;0,I)$ $$ \\begin{align} \u0026p_\\theta(\\mathbf{x}_{0:T}):=p(\\mathbf{x}_T)\\prod^T_{t=1}p_\\theta(\\mathbf{x}_{t-1}|\\mathbf{x}_t) \\\\ \u0026p_\\theta(\\mathbf{x}_{t-1}|\\mathbf{x}_t):=\\mathcal{N}(x_{t-1};\\mu_\\theta(x_t,t),\\Sigma_\\theta(\\mathbf{x}_t,t)) \\end{align} $$ 扩散过程：近似后验$q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)$，被固定在马尔可夫链上并逐渐根据方差表添加高斯噪声得到 $$ \\begin{align} \u0026q(\\mathbf{x}_{1:T}|\\mathbf{x}_0):=\\prod^T_{t=1}q(\\mathbf{x}_t|\\mathbf{x}_{t-1}) \\\\ \u0026q(\\mathbf{x}_t|\\mathbf{x}_{t-1}):=\\mathcal{N}(\\mathbf{x}_t;\\sqrt{1-\\beta_t}\\mathbf{x}_{t-1},\\beta_t\\mathbf{I}) \\end{align} $$2.2 与Langevin方程的关联 $$ m\\frac{d^2x}{dt^2}=-\\gamma\\frac{dx}{dt}+F(x)+\\xi(t) $$ 那么在过阻尼($m\\rightarrow0$)与无保守力$F(x)=0$的情形下，方程可以被整理为 $$ \\frac{dx}{dt}=\\frac{1}{\\gamma}\\xi(t) $$ 那么这与生成扩散模型的扩散过程能够对应上。\n2.3 OU process 2.3.1 Wiener Process 连续时间随机过程，通常一个Wiener process用符号$W_t$描述，有三个性质：\n$W_0=0$ $t\\rightarrow W_t$在正实数范围内几乎处处连续 对所有的$0\\leq s \u003c t$，$W_t-W_s\\sim\\mathcal{N}(0,t-s)$ 2.3.2 Ornstein-Ulhenbeck Process 由wiener process扩展而来的随机过程，由以下随机微分方程描述 $$ dx_t=-\\theta x_tdt+\\sigma dW_t $$ 其中参数$\\theta \u003e 0,\\sigma \u003e 0$，$\\mu$表示回归均值。 同时虽然维纳过程的路径在数学上几乎处处不可微（其在任意点处都无法定义导数），但是在工程和物理上，通常将$\\frac{dW_t}{dt}$视为白噪声，记作$\\xi_t$。并且由于可微性的问题，其离散化需要一些特殊的处理方式： $$ W(t)=\\int^t_{t_0}dt'\\xi(t')=\\int^t_{t_0}dW $$那么其随机积分表述为$\\int^t_{t_0}dt'\\xi(t')f(X_t,t)=\\int^t_{t_0}dW f(x_t,t)$，被称作Riemann-Steltjes积分，在这个基础上，这个积分通常有两种约定形式： Ito约定，起点方案： $$ \\int^t_{t_0}dWf(X_t,t)=\\lim_{dt\\rightarrow0}\\sum^N_{k=0}[W(t_k+dt)-W(t_k)]f(X(t_k),t_k) $$ $t_k=t_0+kdt,N=\\frac{t-t_0}{dt}$\nStratonovich约定，中点方案： $$ \\int^t_{t_0}dWf(X_t,t)=\\lim_{dt\\rightarrow0}\\sum^N_{k=0}[W(t_k+dt)-W(t_k)]f([X(t_k+dt)+X(t_k)]/2,t_k+dt/2) $$2.3.3 OU process的Fokker-Planck方程 形式为 $$ \\frac{\\partial P}{\\partial t}=\\theta \\frac{\\partial}{\\partial x}(xP)+D\\frac{\\partial^2 P}{\\partial x^2} $$ $D=\\sigma^2/2$，这个方程的解是 $$ P(x,t|x',t')=\\sqrt{\\frac{\\theta}{2\\pi D(1-e^{-2\\theta(t-t')})}}exp\\left[-\\frac{\\theta}{2D}\\frac{(x-x'e^{-\\theta(t-t')})^2}{1-e^{-2\\theta(t-t')}}\\right] $$3. 详细内容 3.1 前向（扩散）过程中的非平衡物理 3.1.1 前向扩散的动力学过程 首先作者用一个OU过程描述了真实数据变成白噪声的过程： $$ \\dot{X}=-X+\\sqrt{2}\\xi $$ 其中$\\xi$是一个高斯白噪声，并给定初值$X_0$。 那么利用一些随机微分方程的知识，我们可以知道它的解的形式为： $$ X_t=e^{-t}X_0+\\sqrt{1-e^{-2t}}Z_t $$ 其中$Z_t$代表高斯分布的随机变量。 接着作者为了分析方便，假定初始数据是一个两种高斯分布混合的形式： $$ p(X_0)=\\frac{1}{2}\\mathcal{N}(\\mu,\\mathbf{I}_d)+\\frac{1}{2}\\mathcal{N}(-\\mu,\\mathbf{I}_d) $$那么在这种情况下，利用前述OU过程的方程，我们可以知道： $$ \\begin{align} p(X_t,t)\u0026=\\int dX_0p(X_0)p(X_t|X_0)\\\\ \u0026=\\int dX_0 p(X_0)\\mathcal{N}(X_t;X_0 e^{-t},\\mathbf{I}_d)\\\\ \u0026=\\frac{1}{2}\\mathcal{N}(X_t;\\mu_t,\\mathbf{I}_d)+\\frac{1}{2}\\mathcal{N}(X_t;-\\mu_t,\\mathbf{I}_d) \\end{align} $$ 其中$\\mu_t=\\mu e^{-t}$。 上述的分析可以清楚地让我们看出，为何DDPM可以那样被设计，为何能期望不断叠加高斯噪声最终能得到一个高斯分布的结果。 这是本文中作者采用的模型试验的示意图 3.1.2 扩散过程的涨落定理 扩散过程的公式起点： $$ dX_t=f(X_t,t)dt+\\sqrt{2}dW $$通常的离散化下可得： $$ \\frac{X_{t+dt}-X_t}{dt}=f((1-\\lambda)X_t+\\lambda X_{t+dt}, t+\\lambda dt)+\\eta_t $$ 这里$\\eta_t\\sim \\mathcal{N}(0,2/dt)$ 接着，借助概率密度变换的公式，我们可知： $$ P(X_{t'},t'|X_t,t)=P(\\eta_t)\\left |\\frac{\\partial \\eta_t}{\\partial X_{t'}}\\right | $$ 由前述离散化公式我们可以顺势计算概率密度变换的雅可比行列式 $$ \\left |\\frac{\\partial \\eta_t}{\\partial X_{t'}}\\right |=\\left |\\frac{\\partial (\\frac{X_{t+dt}-X_t}{dt}-f((1-\\lambda)X_t+\\lambda X_{t+dt}, t+\\lambda dt))}{\\partial X_{t+dt}}\\right |\\varpropto e^{-\\lambda\\nabla\\cdot fdt} $$结果带入前式可得 $$ P(X_{t+dt},t+dt|X_t,t)\\varpropto e^{-\\lambda\\nabla\\cdot fdt}e^{-\\frac{|\\dot{X}_t-f(X_t,t)|^2}{4}dt} $$那么结合马尔可夫条件，这种情况下以$X_0$为起点的轨迹的条件概率为： $$ \\begin{align} P(X([T])|X_0)\u0026=\\prod_{t'}P(X_{t'},t'|X_t,t)\\\\ \u0026=\\prod_{t'}e^{-\\lambda\\nabla\\cdot fdt}e^{-\\frac{|\\dot{X}_t-f(X_t,t)|^2}{4}dt}\\\\ \u0026\\varpropto e^{\\int^T_0[-\\lambda\\nabla\\cdot f-\\frac{|\\dot{X}_t-f(X_t,t)|^2}{4}]\\odot^{\\lambda}dt} \\end{align} $$ 这里$\\odot^\\lambda$表示随机积分的$\\lambda-$约定。 事已至此，对比我们上一节提出的OU过程模型公式与作为推导起点的公式，我们可以简单令此处$f=-X$，同时需注意这里是d维的动力学公式，带入前式可得OU过程的轨迹概率为： $$ \\begin{align} P(X([T])|X_0)\u0026=\\prod_{t'}P(X_{t'},t'|X_t,t)\\\\ \u0026\\varpropto exp\\left (-\\int^T_0[\\frac{1}{4}(\\dot{X}+X)^2-\\lambda d]\\odot^{\\lambda}dt\\right ) \\end{align} $$ 在这样的形式下，e指数的部分在物理中被称为action for the path probability，而这样被时间积分的作用函数称作Lagrangian $\\mathcal{L}$。 考察对应的逆过程$\\tilde{X}(s)=X(t),s=T-t$，接着显然有$\\tilde{X}(0)=X(T),\\tilde{X}(T)=X(0),\\dot{\\tilde{X}}(s)=-\\dot{X}(t)$，那么将上述带入前面的前向OU过程可得逆过程的概率： $$ \\begin{align} P[\\tilde{X}([T])|\\tilde{X}_0]\u0026\\varpropto exp\\left (-\\int^T_0ds\\odot^\\lambda[(\\dot{\\tilde{X}}+\\tilde{X})^2/4-\\lambda d]\\right ) \\\\ \u0026=exp\\left (-\\int^T_0dt\\odot^{1-\\lambda}[(-\\dot{X}+X)^2/4-\\lambda d]\\right ) \\end{align} $$那么我们就有： $$ \\begin{align} ln\\left [\\frac{P(X([T])|X_0)}{P[\\tilde{X}([T])|\\tilde{X}_0]}\\right ] \u0026= \\int^T_0dt\\odot^{1-\\lambda}\\left [-\\frac{\\dot{X}\\cdot X}{2}\\right ] - \\int^T_0dt\\odot^{\\lambda}\\left [\\frac{\\dot{X}\\cdot X}{2}\\right ] \\\\ \u0026=\\int^T_0dt\\odot^{\\frac{1}{2}}[-\\dot{X}\\cdot X] \\end{align} $$当然这个式子显然是与熵产生有关的，下面会给出更具体的推导： 从总熵产生开始，有： $$ \\begin{align} \\Delta S_{\\text{tot}} \u0026= \\ln \\left (\\frac{P[X([T])]}{P[\\tilde{X}([T])]}\\right ) \\\\ \u0026= \\ln\\left (\\frac{P(X([T])|X_0)\\cdot p(X(0),0)}{P[\\tilde{X}([T])|\\tilde{X}_0]\\cdot p(X(T),T)}\\right )\\\\ \u0026=\\ln\\left (\\frac{P(X([T])|X_0)}{P[\\tilde{X}([T])|\\tilde{X}_0]}\\right )+\\ln\\left (\\frac{p(X(0),0)}{p(X(T),T)}\\right ) \\end{align} $$ 这里第一项就是前式，我们从推导过程可以知道这个熵产生是由扩散路径造成的，因此可以解释为耗散到环境中的熵，这里作者将这项称为环境的熵变$\\Delta S_{E}$。 而第二项代表起始点和终点系统的两个平衡态的熵变$\\Delta S$ $$ \\Delta S=\\ln \\left [\\frac{exp(-(X(0)-\\mu)^2/2)+exp(-(X(0)+\\mu)^2/2)}{exp(-(X(T)-\\mu e^{-T})^2/2)+exp(-(X(T)+\\mu e^{-T})^2/2)}\\right ] $$做完上述推导，作者简单指出这个过程的积分涨落定理可以接着如下推导： $$ \\begin{align} \\langle e^{-\\Delta S_{tot}}\\rangle \u0026= \\int P[X([T])]e^{-\\Delta S_{tot}}d X([T])\\\\ \u0026=\\int P[\\tilde{X}([T])]d\\tilde{X}([T])\\\\ \u0026=1 \\end{align} $$并且作者对此通过了一个一维OU过程的实验验证了上述数学结果，我们可以看到随着轨迹增加，平均值收敛于1。 3.1.3 随机熵产生(Stochastic entropy production)率 接着前述OU process的描述，其Fokker-Planck方程可以写出： $$ \\frac{\\partial p(X_t,t)}{\\partial t}=-\\nabla\\cdot f(X_t,t)p(X_t,t) + \\sum^d_{i=1}\\frac{\\partial^2 p(X_t,t)}{\\partial X^2_i}=-\\nabla\\cdot J $$ 由此可知这里概率流为$J=f(X_t,t)p(X_t,t)-\\nabla p(X_t,t)$。 这里定义Stochastic entropy为$\\mathbb{S}(t)=-\\ln p(X_t,t)$，那么接着推导这个熵的熵变化率 $$ \\begin{align} \\dot{\\mathbb{S}}(t)\u0026=-\\frac{1}{p(X_t,t)}\\frac{dp(X_t,t)}{dt}\\\\ \u0026=-\\frac{1}{p(X_t,t)}(\\frac{\\partial p(X_t,t)}{\\partial t}+\\nabla p(X_t,t)\\dot{X}) \\end{align} $$ 我们将前面概率流的式子带入可得 $$ \\dot{\\mathbb{S}}(t)=-\\frac{\\partial_t p(X_t,t)}{p(X_t,t)}-f(X_t,t)\\cdot\\dot{X}+\\frac{J\\cdot\\dot{X}}{p(X_t,t)} $$ 在这里观察可以发现第二项$f(X_t,t)\\cdot\\dot{X}$与Langevin方程中的摩擦项$-\\gamma \\dot{x}$有着相似的形式，它可以被看作这个随机过程中环境的热耗散过程，这里作者认为$\\dot{\\mathbb{S}}_E(t)=f(X_t,t)\\dot{X}$，那么就可以定义总的熵产生率为 $$ \\dot{\\mathbb{S}}_{tot}(t)=\\dot{\\mathbb{S}}(t)+\\dot{\\mathbb{S}}_{E}(t)=-\\frac{\\partial_t p(X_t,t)}{p(X_t,t)}+\\frac{J\\cdot\\dot{X}}{p(X_t,t)} $$这里作者通过10000个前向OU过程根据其推导统计了一些熵变数据，图如下 3.2 逆向生成动力学中的非平衡物理 3.2.1 反向过程的随机微分方程 根据前向扩散过程我们来考虑对应的逆向生成过程，首先由贝叶斯定理可得： $$ P(X_t,t|X_{t+dt},t+dt)=\\frac{P(X_{t+dt},t+dt|X_t,t)}{p(X_{t+dt},t+dt)}p(X_t,t) $$接着由扩散过程方程$dX_t=f(X_t,t)dt+\\sqrt{2}dW$，我们可知$X_{t+dt}-X_t=f(X_t,t)dt+\\sqrt{2dt}\\eta_t$，于是 $$ P(X_{t+dt},t+dt|X_t,t)\\varpropto \\exp\\left [-\\frac{(X_{t+dt}-X_t-f(X_t,t)dt)^2}{4dt} \\right ] $$而另一方面 $$ \\begin{align} \\frac{p(X_t,t)}{p(X_{t+dt},t+dt)}\u0026=\\exp[-(\\ln p(X_{t+dt},t+dt)-\\ln p(X_t,t))]\\\\ \u0026=\\exp\\left[-(dX\\cdot\\nabla\\ln p(X_t,t)+dt\\cdot\\frac{\\partial \\ln p(X_t,t)}{\\partial t})\\right] \\end{align} $$将所有上述组件带回最初的公式，并利用一些技巧进行推导如下 $$ \\begin{align} P(X_t,t|X_{t+dt},t+dt)\u0026\\varpropto\\exp\\left[-\\frac{(X_{t+dt}-X_t-f(X_t,t)dt)^2}{4dt}-dX\\cdot\\nabla\\ln p(X_t,t)-dt\\cdot\\frac{\\partial \\ln p(X_t,t)}{\\partial t}\\right]\\\\ \u0026\\varpropto\\exp\\left[-\\frac{(X_{t+dt}-X_t-f(X_t,t)dt)^2+4(X_{t+dt}-X_t)\\nabla\\ln p(X_t,t)dt+\\mathcal{O}(dt^2)}{4dt}\\right]\\\\ \u0026\\thickapprox\\exp\\left[-\\frac{(X_{t+dt}-X_t)^2-2(X_{t+dt}-X_t)f(X_t,t)dt+2(X_{t+dt}-X_t)2\\nabla\\ln p(X_t,t)dt+f^2(X_t,t)dt^2}{4dt}\\right]\\\\ \u0026=\\exp\\left[-\\frac{(X_t-X_{t+dt})^2+2(X_t-X_{t+dt})[f(X_t,t)-2\\nabla\\ln p(X_t,t)]dt+f^2(X_t,t)dt^2}{4dt}\\right]\\\\ \u0026\\thickapprox\\exp\\left[-\\frac{(X_t-X_{t+dt})^2+2(X_t-X_{t+dt})[f(X_t,t)-2\\nabla\\ln p(X_t,t)]dt+[f(X_t,t)-2\\nabla\\ln p(X_t,t)]^2dt^2}{4dt}\\right]\\\\ \u0026=\\exp\\left [-\\frac{\\lVert(X_t-X_{t+dt})+[f(X_t,t)-2\\nabla\\ln p(X_t,t)]dt\\rVert^2}{4dt}\\right ] \\end{align} $$将这个形式对比正向扩散过程，我们可以简单类比得到逆向动力学的方程为 $$ \\dot{X}=f(X_t,t)-2\\nabla\\ln p(X_t,t)+\\sqrt{2}\\xi $$ 这个结果与Brian DO Anderson. Reverse-time diffusion equation models. Stochastic Processes and their Applications, 12(3):313–326, 1982. 结果相符合\n3.2.2 训练的评价函数 Denoise Net往往有这样的loss形式$\\mathcal{L}(\\theta)=E[\\lVert s_{\\theta}(x,t)-\\nabla\\ln p(x,t)\\rVert^2]$（可以参考A Connection Between Score Matching and Denoising Autoencoders），而参考引文Learning Mixtures of Gaussians Using the DDPM Objective我们另外可以知道$\\nabla \\ln p(X_t,t)=\\tanh(\\mu_t^TX_t)\\mu_t-X_t$，这部分将在后面有用\n3.2.3 势能和自由能 作者参考这篇论文Spontaneous Symmetry Breaking in Generative Diffusion Models中推导出的generative SDE形式，并结合向前推导的逆向过程方程$\\dot{X}=f(X_t,t)-2\\nabla\\ln p(X_t,t)+\\sqrt{2}\\xi$，令$t=T-s$可得 $$ \\begin{align} d\\tilde{X}_s\u0026=[2\\nabla\\ln p(\\tilde{X}_s,T-s)-f(\\tilde{X}_s,T-s)]ds+\\sqrt{2}dW\\\\ \u0026=-\\nabla U(\\tilde{X}_s,T-s)+\\sqrt{2}dW \\end{align} $$ 这里$U(\\tilde{X}_s,T-s)$可以看作逆过程的势能（参考过阻尼情况下的朗之万方程，广义位移与力可以直接关联）。 同样参考上述论文和此处的推导形式，可以写出 $$ \\begin{align} U\u0026=-2\\ln p(\\tilde{X}_s,T-s)+\\int^{\\tilde{X}_s}_0 f(Z,T-s)dZ\\\\\\ \u0026=\\frac{1}{2}\\tilde{X}_s^2-2\\ln\\cosh(\\tilde{X}_s\\cdot\\mu e^{-(T-s)})\\\\ \u0026=\\frac{1}{2}X_t^2-2\\ln\\cosh(X_t\\cdot \\mu e^{-t}) \\end{align} $$然后参考前向扩散过程，我们知道： $$ \\begin{align} p(X_t,t)\u0026=\\int\\mathcal{N}(X_t;X_0e^{-t},\\Sigma_t I_d)p(X_0)dX_0\\\\ \\nabla \\ln p(X_t,t)\u0026=\\Sigma^{-1}\\left[\\frac{\\int\\mathcal{N}(X_t;X_0e^{-t},\\Sigma_t I_d)p(X_0)X_0 e^{-t}dX_0}{\\int\\mathcal{N}(X_t;X_0e^{-t},\\Sigma_t I_d)p(X_0)dX_0}-X_t\\right]\\\\ \u0026=\\Sigma^{-1}[\\langle X_0e^{-t}\\rangle-X_t] \\end{align} $$接着利用贝叶斯定理 $$ \\begin{align} P(X_0|X_t)\u0026=\\frac{P(X_t|X_0)p(X_0)}{p(X_t)}\\\\ \u0026=\\frac{\\mathcal{N}(X_0 e^{-t},\\Sigma_t I_d)p(X_0)}{p(X_t)}\\\\ \u0026\\varpropto \\exp\\left[-\\frac{1}{2}(X_t-X_0 e^{-t})^T\\Sigma^{-1}(X_t-X_0e^{-t})+\\ln p(X_0)\\right] \\end{align} $$ 据此我们可以写出平衡态哈密顿量$\\mathcal{H}(X_0|X_t)=\\frac{1}{2}(X_t-X_0 e^{-t})^T\\Sigma^{-1}(X_t-X_0e^{-t})-\\ln p(X_0)$,那么可以写出对应的配分函数$Z(X_t,t)=\\int e^{-\\mathcal{H}(X_0|X_t)}dX_0$，接着就可以得到自由能形式$F(X_t,t)=-\\frac{1}{\\beta}\\ln Z(X_t,t)$，这里取$\\beta=\\Sigma^{-1}_t$，那么有 $$ \\begin{align} \\nabla F(X_t,t)\u0026=\\nabla\\left(-\\frac{1}{\\beta}\\ln Z(X_t,t)\\right)\\\\ \u0026=-\\frac{1}{\\beta}\\frac{\\nabla Z(X_t,t)}{Z(X_t,t)}\\\\ \u0026=-\\langle X_0e^{-t}\\rangle+X_t \\end{align} $$ 那么结合上面推导的$\\nabla\\ln p(X_t,t)$的形式得到$\\nabla F(X_t,t)=-\\frac{1}{\\beta}\\nabla\\ln p(X_t,t)$，结合作者这里的mixture Gaussian情景并参考前面U的推导过程可以简单得到 $$ F=-\\frac{1}{\\beta}\\ln\\cosh(X_t\\cdot\\mu_t)+\\frac{1}{2\\beta}X_t^2 $$另外参考最开始reverse SDE的推导中的$\\nabla U$的形式部分我们可以写出$-\\nabla \\tilde{F}=2\\nabla\\ln p-f$，进而我们能够得到 $$ \\tilde{F}=2\\beta F+\\int fd\\tilde{X}_s $$ 这里带入$F$形式后可以观察到$\\tilde{F}$与最开始定义的potential $U$的形式相一致，那么观察reverse SDE的形式后我们可以从物理上对逆向动力学过程解释为平均来说指向自由能梯度向下，即最小化自由能的过程，带入DDPM中逆向过程对应于生成过程，我们可以认为生成的样本满足最小自由能原理。\n根据这个potential,作者展示了reverse dynamics中的自发对称破缺和相图 结合我们上述得到的最小自由能解释，我们可以知道这样的生成系统在哪些区域可以正确生成样本，即如果进入no symmetry breaking或者unstable symmetry breaking情形下，我们无法在X非0处期望有U极小值存在，这将在逆向过程中意味着生成采样失败。\n3.2.4 逆向动力学的涨落定理及其熵产生 参考上一节推导的最初的包含potential U形式的reverse SDE形式并带入后续得到的U的具体形式，我们可以更进一步写出reverse SDE: $$ dX_t=-(2\\tanh(\\mu_t^TX_t)\\mu_t-X_t)dt+\\sqrt{2}dW $$ 统一时间方向为diffusion的正向，我们令$s=T-t$ $$ d\\tilde{X}_s=[2\\tanh(\\mu_{T-s}^T\\tilde{X}_{s})\\mu_{T-s}-\\tilde{X}_s]ds+\\sqrt{2}dW $$ 后面的推导过程都可以仿照前面的前向动力学部分，最终作者得到 Reverse dynamics的积分涨落定理 $$ \\langle e^{-S_{tot}}\\rangle=1 $$ 3.2.5 玻璃态转变 作者在这一节使用自旋玻璃有关的推导，并采用自旋玻璃研究中常用的Franzi-Parisi potential来表征了一下这个系统，如下图\n在自旋玻璃的研究中，通常认为在Franzi-Parisi potential表征下，Q\u0026gt;0处出现一个次级极小值，则意味着系统在低温下倾向于进入一个亚稳态，着同样对应于系统的玻璃态。而在这里通过Franzi-Parisi势的表征可以看到对于reverse dynamics的生成过程同样是存在一个物理意义上的玻璃态转变的\n","date":"2025-05-13T00:00:00Z","permalink":"http://localhost:1313/p/nonequilbrium-physics-of-generative-diffusion-models/","title":"Nonequilbrium physics of generative diffusion models"},{"content":"LoRA \u0026amp; Galore\n1. LoRA 1.1 背景简介 目前NLP领域常用的范式就是选择一个已经预训练好的LLM模型作为基座然后做微调来完成自己的任务，但是全参数的微调在目前参数量过大的LLM模型上过于昂贵了，LoRA就是面向这样一个问题而提出的高效微调方法。\n简单说来，LoRA基于这样一个事实\nthe learned over-parametrized models in fact reside on a low intrinsic dimension\nMeasuring the Intrinsic Dimension of Objective Landscapes\nIntrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning\n作者据此假设权重更新的时候亦存在一个低的\u0026quot;intrinsic dimension\u0026quot;，这才有了LoRA(Low-Rank Adaptation approach)。在实际操作中，LoRA就是在微调过程中只训练一些全连接层，而这些全连接层的参数还是经过两个低秩矩阵分解后的，只需要更新低秩矩阵参数即可，如下图\n1.2 理论方法 原来的模型Dense层的参数 $$ W\\in \\mathbb{R}^{d\\times k} $$微调更新\n$$ W_0+\\Delta W=W_0+BA\\text{, }B\\in\\mathbb{R}^{d\\times r}\\\u0026A\\in\\mathbb{R}^{r\\times k} $$1.3 应用实际的注意点 We leave the empirical investigation of adapting the MLP layers, LayerNorm layers, and biases to a future work.\nLoRA本文工作作者只将这个方法应用到了Attension的权重部分，即$W_q,W_k,W_v,W_o$上，而不管其他的MLP等层。并且尽管Attension可能是有多头的，但是这个工作里将每种权重$W_q$等分别视作一整个矩阵。\n2. GaLore 2.1 背景简介 这个方法是LoRA的延续/改进，同样是为了实现LLM的高效微调，LoRA有效果和全参数微调相比不够好的问题。同时，整体上GaLore的思路是继承了low rank structure的思想的。\n2.2 理论方法 LoRA是认为over parametered LLM的参数矩阵是可以使用low rank矩阵来分解的，而Galore在LoRA的基础上更进了一步，它认为权重更新的梯度矩阵G是缓变的低秩结构。\n2.2.1 可逆网络的梯度形式 定义：可逆网络$\\mathcal{N}(x):=\\mathcal{N}\\_L(\\mathcal{N}\\_{L-1}(...\\mathcal{N}\\_1(x)))$，$J_l:= \\text{Jacobian} (\\mathcal{N}\\_L)... \\text{Jacobian} (\\mathcal{N}\\_{l+1})$，$f_l:=\\mathcal{N}_l(...\\mathcal{N}_1(x))$，第l层的权重矩阵为$W_l$有梯度$G_l$，batchsize为1。简化一点我们可以用下图说明：\n通常我们有数值回归任务和分类任务两类任务，他们的Loss function通常为$\\frac{1}{2}(y-f_L)^2$和$-log(\\frac{exp(z_{y_i})}{\\sum^K_{i=1}exp(z_i)})$，更进一步 当$\\varphi=\\frac{1}{2}(y-f_L)^2$，那么我们有 $$ \\begin{align*} G_l \u0026= \\frac{\\partial\\varphi}{\\partial W_l} \\\\\\ \u0026= \\frac{\\partial\\varphi}{\\partial f_L}\\frac{\\partial f_L}{\\partial W_l} \\\\\\ \u0026= -(y-f_L)\\cdot J_l \\cdot \\frac{\\partial f_l}{\\partial W_l} \\\\\\ \u0026= J^T_l\\cdot -(y-f_L)\\cdot \\frac{\\partial f_l}{\\partial W_l} \\end{align*} $$ 简单有 $$ f_l = W_l \\cdot f_{l-1} $$ 所以 $$ \\frac{\\partial f_l}{\\partial W_l} = f^T_{l-1} $$ 而我们可以认为$f_{l,0}=0$，所以 $$ \\begin{align*} f_L \u0026= \\frac{\\partial f_L}{\\partial f_l}\\cdot f_l \\\\\\ \u0026= J_l \\cdot W_lf_{l-1} \\end{align*} $$ 全部代入最初的结果可得 $$ G_l=-J^T_l(y-J_lW_lf_{l-1})f^T_{l-1} $$ 这与文中Appendix B.1的公式6形式一致，差一个符号或许可以解释为梯度下降再取一个负号\n而当$\\varphi=-log(\\frac{exp(y^Tf_L)}{\\mathbf{1}^Texp(f_L)})$时， 首先我们需要拿来一个投影矩阵$P_{\\mathbf{1}}^{\\perp}=I-\\frac{1}{K}\\mathbf{1}^T\\mathbf{1}$，我们注意到这个投影矩阵是半正定的同时它本质上是把任意向量投影到$\\mathbf{1}$向量的正交补空间，即经过投影后的向量一定与$\\mathbf{1}$正交，这意味着投影后的向量一定是均值为0的（这个性质后面能用到）。接着我们利用这个投影矩阵定义新的$\\hat{f}:=P_{\\mathbf{1}}^{\\perp}f$，从$P_{\\mathbf{1}}^{\\perp}$的形式我们可以知道$f=\\hat{f}+c\\mathbf{1}$，那么我们可以知道 $$ \\varphi=-ln(\\frac{exp(c)exp(y^T\\hat{f})}{exp(c)\\mathbf{1}^Texp(\\hat{f})})=-(y^T\\hat{f}-ln(\\mathbf{1}^Texp(\\hat{f}))) $$ 接着对$exp(\\hat{f})$进行泰勒展开，保留到二阶 $$ \\begin{align*} exp(\\hat{f}) \u0026= \\mathbf{1}^T(1+\\hat{f}+\\frac{1}{2}\\hat{f}^T\\hat{f}) \\\\\\ \u0026= (K + 0 + \\frac{1}{2}\\hat{f}^T\\hat{f}) \\\\\\ \u0026= K(1+\\frac{1}{2K}\\hat{f}^T\\hat{f}) \\end{align*} $$ 带入可得 $$ \\varphi = -(y^T\\hat{f}-ln(1+\\frac{1}{2K}\\hat{f}^T\\hat{f})-lnK) $$ 那么 $$ \\begin{align*} G_l \u0026= \\frac{\\partial\\varphi}{\\partial W_l} \\\\\\ \u0026= \\frac{\\partial\\varphi}{\\partial f_L}\\frac{\\partial f_L}{\\partial W_l} \\\\\\ \u0026= J^T\\_l\\frac{\\partial\\hat{f}\\_l}{\\partial f_l}\\frac{\\partial\\varphi}{\\partial\\hat{f}\\_l}\\hat{f}^T\\_{l-1} \\\\\\ \u0026= -J^T\\_lP^T\\_{\\mathbf{1}}(y^T-\\frac{\\gamma}{K}\\hat{f}\\_L)\\hat{f}^T\\_{l-1} \\\\\\ \u0026= -J^T\\_lP^T\\_{\\mathbf{1}}(y^T-\\frac{\\gamma}{K}J\\_lW\\_lf\\_{l-1})\\hat{f}^T\\_{l-1} \\end{align*} $$ 其中$\\gamma=(1+\\frac{1}{2K}\\hat{f}^T\\hat{f})^{-1}$，并且在small logits下$||P^T_\\mathbf{1}f_L||_{\\infty}\\ll\\sqrt{K}$，那么$\\gamma\\thickapprox1$。 同样， 这与文中Lemma B.2形式一致，相差一个负号应该是梯度下降取负号\n2.2.2 Low Rank Gradient 经过上面的证明我们可以知道，可逆网络的梯度有这样的通用形式 $$ G_l=A-BW_lC $$ 我们假设采用SGD的更新形式$W_l^t=W^{t-1}\\_l+\\eta G^{t-1}\\_l$代入， $$ G^t\\_l=A-B(W^{t-1}\\_l+\\eta G^{t-1}\\_l)C=G^{t-1}\\_l-\\eta BG^{t-1}\\_lC $$ 接着需要进行如下定义：$S:=C\\otimes B$，$g_t:=vec(G_t)\\in R^{mn}$是对$G_t\\in R^{m\\times n}$的向量化。接着，由$vec(BWC)=(C^T\\otimes B)vec(W)$，我们可得 $$ g_t = (I-\\eta S)g_{t-1} $$ 接着我们就开始尝试对$G_l$进行low rank approximation，paper里这部分数学过程里面的原理很多可以参考UBC Lecture Note 首先我们需要stable rank $$ \\text{stable-rank}(G_t):=\\frac{||G_t||\\_F^2}{||G_t||^2_2} $$ 其中$||A||^2_F$叫做Frobenius norm，定义为$||A||^2_F:=tr(AA^T)=\\sum_{i,j}A^2_{i,j}=\\sum_i\\sigma_i^2$。而另一个$||A||\\_2$表示matrix 2-norm（矩阵2范数），也叫谱范数(spectral norm)，而矩阵的2范数就是对矩阵做SVD分解后得到的最大奇异值$\\sigma_{max}$。因此A的stable rank满足 $$ \\frac{||A||^2\\_F}{||A||^2}=\\frac{\\sum\\_i\\sigma\\_i^2}{max\\_i\\sigma_i^2} $$ 从这我们可以看出stable rank相比rank，虽不能表示所有的正奇异值个数，但可近似掉较小的奇异值。 $$ \\begin{align*} ||G_t||^2_F \u0026= ||g_t||^2_F=||(I-\\eta S)^tg_0||^2_F=||(I-\\eta S)^tg_0^{\\parallel}||^2_F+||(I-\\eta S)^tg_0^{\\perp}||^2_F \\\\\\ \u0026\\leq (1-\\eta\\lambda_2)^{2t}||g_0^{\\perp}||^2_F+(1-\\eta\\lambda_1)^{2t}||g_0^{\\parallel}||^2_F \\end{align*} $$ 其中$\\lambda_1\u003c\\lambda_2$是S最小的两个特征向量，$\\lambda_1$是最小的特征值，简并度为$\\kappa_1$。$g_0^{\\parallel}$是$lambda_1$对应的本征子空间$\\nu_1$，我们将$g_0$分解为$g_0=g_0^{\\parallel}+g_0^{\\perp}$。\n而从另一个角度出发，根据我们对gradient的低秩假设，设$G_0^{\\parallel}$有rank $L$，对其做SVD： $$ G\\_0^{\\parallel}=\\sum\\_{l=1}^Lc\\_l z\\_l y^T\\_l $$ $c_l$为奇异值，$z_l,y_l$为正交单位向量，那么 $$ g^{\\parallel}\\_0=vec(G\\_0^{\\parallel})=\\sum\\_{l=1}^Lc\\_l(y\\_l\\otimes z\\_l)=\\sum\\_{l=1}^Lc\\_lv\\_l，v\\_l\\in\\nu\\_1 $$ 这样我们就可以注意到这个本征子空间是完全正交对角化的，进而我们就以此注意到$||g\\_0^{\\parallel}||^2\\_2=||g\\_0^{\\parallel}||^2\\_F=||G\\_0^{\\parallel}||^2\\_F$。\n这样的话，整合上述知识，首先从matrix 2-norm的定义和前述的$g_t=vec(G_t)$的表达式出发 $$ \\begin{align*} ||G_t||_2 \u0026= max\\text{ }z^TG_ty \\\\\\ \u0026= max (y\\otimes z)^Tg_t \\\\\\ \u0026= max (y\\otimes z)^T(I-\\eta S)^tg_0 \\\\\\ \u0026\\geq (1-\\eta \\lambda_1)^tmax_l v_l^Tg_0 \\end{align*} $$ 由于$v_l$对应于最小本征值$\\lambda_1$的本征子空间$\\nu_1$的单位向量，那么$v_l^Tg_0$可以看作$G_0$向$\\nu_1$的投影相关，那么再由matrix 2-norm的定义可以发现，$max(v_l^Tg_0)=||G^{\\parallel}_0||_2$。 最终，我们对$sr(G_t)$的分式中的分子取上界，分母取下界就可以得到最后 $$ sr(G_t)\\leq sr(G_0^{\\parallel})+(\\frac{1-\\eta \\lambda_2}{1-\\eta \\lambda_1})^{2t}\\frac{||G_0^{\\perp}||^2_F}{||G^{\\parallel}_0||_2} $$这样我们就得到了$\\text{stable-rank}(G_t)$的上界形式，更进一步的让我们回到梯度$G_t$本身 $$ G^l_t = A-BW^lC = (a - BW^lf_l)f_l^T $$ 如果$B$是满秩的，而$\\text{rank}(f)=N' \u003c n$，\n那么一方面，我们知道$C=ff^T\\in \\mathbb{R}^{n\\times n}$，由于$\\text{rank}(\\{f\\}^N) \u003c n$，那么我们令$\\{u\\}^{n-N}$作为$\\mathbb{R}^n$中$f^N$所张成的空间的补空间的正交基底，同时令$\\{e\\}^m$作为$\\mathbb{R}^m$的任意正交基底，那么显然$\\{u\\otimes e\\}$即可以作为最小本征值0的最小本征空间$\\nu_1$的基底，那么我们把$G_{t_0}$投影到$\\nu_1$上即是 $$ G_{t_0}^{\\parallel}=\\sum_{j=1}^{n-N}\\sum_{k=1}^{m}c_{jk}u_je_k^T=\\sum_{j=1}^{n-N}u_j\\sum_{k=1}^{m}(c_{jk}e_k)^T $$ 我们知道$\\text{stable-rank}(G^{\\parallel}\\_{t_0})\\leq\\text{rank}(G^{\\parallel}\\_{t_0})$（可参考Stable Rank and Intrinsic Dimension of Real and Complex Matrices中2.1）,而根据前式情况我们可知$\\text{rank}(G^{\\parallel}_{t_0})\\leq(n-N)$。\n同时另一方面，$f^N$可以被分解为N个rank为1的矩阵之和，即$f=\\sum_{j=1}^Nb_jf_j$，那么 $$ G_t=(a-BWf)f^T=(a-BWf)(\\sum_{j=1}^Nb_jf_j)^T=\\sum_{j=1}^Nb_j(a-BWf)f_j^T $$ 那么显然我们可知$\\text{rank}(G)\\leq N$。\n所以综上因为$N \u003c n$，我们可知$\\text{sr}(G_t)\\leq min(n-N,N)\\leq n/2$\n终于，大功告成，我们由此可知作为梯度$G_t$的rank的近似stable-rank是不高于n/2的，有着显著的low rank特性。\n","date":"2025-01-29T00:00:00Z","permalink":"http://localhost:1313/p/mathematical-introduction-to-low-rank-structure-from-lora-galore/","title":"Mathematical Introduction to Low-Rank structure from LoRA \u0026 Galore"},{"content":"原文地址\n1. 论文简介 在生命系统中存在在外力作用下偏离平衡态的系统，在非平衡稳态下表现出某种选择现象，这打破了平衡态下的对称性。作者通过矩阵树理论(matrix-tree theorem)推导出了这样的对称性破缺所对应的热力学上下限，并且证明了这个限制只受热力学和非平衡驱动力决定，与具体动力学过程无关。并且通过这套理论作者计算了动力学校准(kinetic proofreading)中的热力学限制。\n2. 理论基础 2.1 非平衡稳态 从可逆的化学反应过程考虑 $$\\sum_m\\nu_mX_m+X_i\\overset{k_{ji}}{\\underset{k_{ij}}{\\rightleftharpoons}}X_j+\\sum_m\\nu_mX_m$$ $\\sum_m\\nu_mX_m$为反应过程中催化剂机制 根据化学反应中的Law of mass action，这个过程可以简化成 $$X_i\\overset{k_{ji}\\prod_m[X_i]^{\\nu_m}}{\\underset{k_{ij}\\prod_m[X_i]^{\\nu_m}}{\\rightleftharpoons}}X_j$$ 我们得到有效转换率$\\hat{k}\\_{ij} \\equiv k_{ij}\\prod_m[X\\_m]^{\\nu_m}$，$[X\\_m]$表示化学成分$X\\_m$的浓度，归一化$p\\_m=[X\\_m]/\\sum\\_m[X\\_m]$后，我们可以得到以下方程\n$$\\frac{dp_i}{dt}=\\sum_{j(\\neq i)}\\hat{k}_{ij}p_j-\\hat{k}\\_{ji}p_i$$同时每两组相邻的物质转换满足局域细致平衡 $$\\frac{\\hat{k}\\_{ij}}{\\hat{k}\\_{ji}}=\\frac{k_{ij}}{k_{ji}}=e^{\\beta(F_{ij}-\\Delta E_{ij})}$$ $F_{ij}$代表从$i$到$j$的非平衡热力学力，在这里，由于催化反应造成的非线性可以用一个系数$\\omega$概括，这样写成$\\hat{k}\\_{ij}=\\omega\\_{ij}(p)k_{ij}$和$\\hat{k}\\_{ji}=\\omega_{ji}(p)k_{ji}$，为了保证细致平衡，$\\omega_{ji}(p)=\\omega_{ij}(p)$\n2.2. 生成树 鉴于我们所使用的环境背景，这里只讨论无向图。在无向图中，若任意两个顶点之间都能够连通，则称此无向图为连通图。生成树为无向连通图中极小的连通子图，生成树包含连通图中所有的顶点并且任意两个之间有且仅有一条通路。生成树的边数为顶点数-1，可以简单的说生成树是无环的连通子图。下图就是一个例子：a为原连通图，b是其对应的生成树。 2.3. 矩阵树理论 让我感到奇怪的是，搜索资料的时候发现图论中的矩阵树理论指的是生成树的数量与拉普拉斯阵的关系1\n(the Matrix-Tree Theorem) Let G be a finite connected graph without loops, with laplacian matrix $L = L(G)$. Let $L_0$ denote $L$ with the last row and column removed (or with the ith row and column removed for any i). Then $$det(L_0) = \\kappa(G)$$ 后面我也没有看出这个”矩阵树理论“与论文中所用有何关系。 不过论文给出的另一个参考文献有另外的描述2\nKirchhoff\u0026rsquo;s theorem now states that the steady state solution $\\overline{p}_i$ is given by $$\\overline{p}\\_i=\\frac{S_i}{S},$$ where $$S_i=\\sum^M_{\\mu=1}A(T_i^{\\mu}(G)),S=\\sum^N_iS_i$$ To every $T_i^{\\mu}(G)$ we assign an algebraic value $A(T_i^{\\mu}(G))$ by multiplying all transition probabilities $\\langle i|j\\rangle$ whose edges occur in $T_i^{\\mu}(G)$ in the direction to i from j.\n用上面这张图来解释非平衡稳态的矩阵树理论，图(a)举了一个例子，假设一个非平衡过程各态/各物质转变关系如图(a)左侧一样。那么我们可以从图论的视角看这个问题，将这个多节点过程对应的无向图分解为它所对应的生成树（即右侧的$T_1$, $T_2$, $T_3$）。 当稳态情形满足$\\omega_{ij}(p^{ss})\\neq0,\\forall i,j$（即每个过程均可逆），我们就可以借助上述生成树分解的视角（如图b）得到 $$p_k^{ss}=\\frac{\\sum_{\\mu}A_k(T_\\mu;p^{ss})}{\\sum_k\\sum_\\mu A_k(T_\\mu;p^{ss})}$$ 其中$A_k(T_\\mu;p^{ss})$表示在稳态$p^{ss}$情况下第$\\mu$个生成树对第$k$个节点的贡献，其计算可以通过图c来理解. 图c展示如何计算$A_1(T_3;p^{ss})$。我们先得到生成树$T_3$。然后因为生成树满足任意两点有且仅有一条通路，那么每条边可以给定唯一的方向，使得整条通路从其余顶点指向目标态1。最后$A_1(T_3;p^{ss})$为“有向化”后的生成树的边对应的等效速率的连乘$\\hat{k}\\_{13}\\hat{k}\\_{32}\\hat{k}\\_{34}$，又由2.1中所说$\\hat{k}\\_{ij}=\\omega\\_{ij}(p)k_{ij}$可解耦为热力学部分$k$和非线性动力学部分$\\omega(p)$，则$A_1(T_3;p^{ss})=\\hat{k}\\_{13}\\hat{k}\\_{32}\\hat{k}\\_{34}=\\omega\\_{13}\\omega\\_{32}\\omega\\_{34}k_{13}k_{32}k_{34}=\\Omega(T_3;p^{ss})\\hat{A}\\_1(T_3)$ 图d展示了我们从矩阵树理论能得到的一个有意思的推论：对某个生成树，$A_i(T_\\mu)/A_j(T_\\mu)$只与$i$，$j$之间的反应路径有关，并且不包含非线性部分。以图d为例 $$ \\frac{A_1(T_3)}{A_4(T_3)}=\\frac{\\hat{k}\\_{13}\\hat{k}\\_{34}\\hat{k}\\_{32}}{\\hat{k}\\_{31}\\hat{k}\\_{43}\\hat{k}\\_{32}}=\\frac{k_{13}k_{34}k_{32}\\omega_{13}\\omega_{34}\\omega_{32}}{k_{31}k_{43}k_{32}\\omega_{31}\\omega_{43}\\omega_{32}}=\\frac{k_{13}k_{34}}{k_{31}k_{43}}=K^{eq}_{14}(T_3) $$3. 结果结论 3.1 非平衡对称破缺的上下限 lemma1 $$ \\begin{matrix} \\frac{\\sum_i a_i}{\\sum_i b_i}\\in\\left[min\\left(\\frac{a_i}{b_i}\\right), max\\left(\\frac{a_i}{b_i}\\right)\\right] \u0026 a_i,b_i \u003e 0 \\end{matrix} $$ 证明： $$ \\begin{aligned} \\frac{a_i}{b_i}\u0026\\leq max(\\frac{a_i}{b_i}) \\\\\\\\ a_i\u0026\\leq max(\\frac{a_i}{b_i})b_i \\\\\\\\ \\sum_i a_i\u0026\\leq\\sum_imax(\\frac{a_i}{b_i})b_i \\\\\\\\ \\sum_i a_i\u0026\\leq max(\\frac{a_i}{b_i})\\sum_ib_i \\\\\\\\ \\frac{\\sum_i a_i}{\\sum_i b_i}\u0026\\leq max(\\frac{a_i}{b_i})\\\\\\\\ \\text{同理 }min\u0026(\\frac{a_i}{b_i})\\leq\\frac{\\sum_i a_i}{\\sum_i b_i} \\end{aligned} $$ 我们来计算任意两态的比值(由2.3中结论) $$ \\frac{p^{ss}\\_i}{p^{ss}\\_j}=\\frac{\\sum_\\mu A_i(T_\\mu ;p^{ss})}{\\sum_\\mu A_j(T_\\mu ;p^{ss})} $$ 带入之前结果 $$ min(\\frac{A_i(T_\\mu ;p^{ss})}{A_j(T_\\mu ;p^{ss})})\\leq\\frac{p^{ss}\\_i}{p^{ss}\\_j}\\leq max(\\frac{A_i(T_\\mu ;p^{ss})}{A_j(T_\\mu ;p^{ss})}) $$ 由2.3中的推论，我们知道$A_i/A_j$只与$i,j$之间的反应路径有关，即只与生成树的选择有关，所以 $$ \\frac{p^{ss}\\_i}{p^{ss}\\_j}\\leq max(\\frac{A_i(T_\\mu ;p^{ss})}{A_j(T_\\mu ;p^{ss})})=\\frac{A_i(T_{max} ;p^{ss})}{A_j(T_{max} ;p^{ss})}=\\prod\\frac{k_{mn}}{k_{nm}}=\\prod e^{\\beta(F_{mn}-\\Delta E_{mn})}=K^{eq}\\_{ij}(T_{max}) $$ 对$p^{ss}_i/p^{ss}_j$的下界同理。至此，我们便看到两个稳态概率比值的上下限与非线性项和非平衡动力学无关。\n3.2 动力学校准(kinetic proofreading) 动力学校准指的是在一些生命过程中，准确性会受到热平衡的限制，因此有人认为会存在利于动力学分辨的耗能的中间步骤。这里作者借助了一个酶(E)与正确的底物(EW)或错误的底物(ER)结合的模型，这个模型中，每种结合态都有对应加*的激活态，如下图：\n整个过程不仅包含平衡态的平衡能量差，还包括驱动整个过程远离平衡态的化学势$\\Delta\\mu$\n结合3.1中的利用矩阵树理论得到的非平衡稳态概率比值上下限，得到对应这个动力学过程的错误率$p_{EW^*}/p_{ER^*}$范围\n其中$\\eta_e=e^{-\\beta\\epsilon}$为平衡能量差导致的平衡错误率，而动力学校准过程额外有化学势的影响给出了新非平衡稳态的范围，二者直观对比如下图（红线和蓝线为非平衡错误率上下限，黄线为平衡态错误率），可以看到这个化学势驱动力事实上既可能减少也可能增加错误率： 3.3 反应扩散方程图案 作者举的这个例子从原理上与3.2本质上一致，都是因为过程中存在耗能过程导致非平衡，表现在模型上路径中存在额外的耗能路径，利用矩阵树定理计算得到整个过程的新的上下限。 The Matrix Tree Theorem (mit.edu)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSchnakenberg J. Network theory of microscopic and macroscopic behavior of master equation systems[J]. Reviews of Modern physics, 1976, 48(4): 571.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-07-02T00:00:00Z","permalink":"http://localhost:1313/p/thermodynamic-bounds-on-symmetry-breaking-in-linear-and-catalytic-biochemical-systems/","title":"Thermodynamic Bounds on Symmetry Breaking in Linear and Catalytic Biochemical Systems"},{"content":"原文地址 实验源码\n原文解读 这篇文章主要介绍了作者实现的物理问题的深度符号回归方法，从物理数据中预测可能的解析形式。（P.S. 作者推特上说这个工作做他们做了一年半）\n","date":"2023-04-18T00:00:00Z","permalink":"http://localhost:1313/p/deep-symbolic-regression-for-physics-guided-by-units-constraints-toward-the-automated-discovery-of-physical-laws/","title":"Deep symbolic regression for physics guided by units constraints: toward the automated discovery of physical laws"}]